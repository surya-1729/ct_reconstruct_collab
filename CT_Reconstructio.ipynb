{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CT_Reconstructio.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surya-1729/ct_reconstruct_collab/blob/main/CT_Reconstructio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oEsLh5Egr3l_"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "import torchvision.datasets as dset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from skimage.transform import radon,rescale,resize\n",
        "\n",
        "#import torchvision.transforms as transforms\n",
        "\n",
        "input_traindata = dset.MNIST( root=\"/content/Mnist\", train = True, transform = None,download= True) #Downloading data\n",
        "\n",
        "ny,nx = input_traindata.data[0].shape #storing image shape matrix in nx,ny\n",
        "input_traindata = input_traindata.data  # taking images\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def getRadonMatrix(theta,ny,nx):\n",
        "    colum_of_A = radon(np.zeros((ny,nx)), theta=theta)  #  this is just to know the size of this\n",
        "    A = np.zeros((colum_of_A.size,nx*ny))\n",
        "    for i in range(ny):\n",
        "        for j in range(nx):\n",
        "            basis_vec = np.zeros((ny,nx))\n",
        "            basis_vec[i,j] = 1\n",
        "            colum_of_A = radon(basis_vec, theta=theta)\n",
        "            A[:,j+i*nx] = np.reshape(colum_of_A, colum_of_A.size)\n",
        "            \n",
        "    return A"
      ],
      "metadata": {
        "id": "Xnbm5l5Xssok"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SinogramDataset(Dataset):\n",
        "    def __init__(self,image_data,A,theta,noise_level,):  #Custom dataset taking Imagedataset ,theta,noise_level and genrate a dataset\n",
        "        self.image_data =image_data\n",
        "        self.noise_level = noise_level\n",
        "        self.A = A\n",
        "        self.theta =theta\n",
        "    def __len__(self):\n",
        "        return len(self.image_data)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        label = self.image_data[idx].double()/255\n",
        "        ny,nx = self.image_data[idx].shape\n",
        "        vec_img = torch.reshape(self.image_data[idx],(1,ny*nx)).double()/255# genearating Vec_image\n",
        "        sinogram = vec_img@self.A.T\n",
        "        #sinogram = torch.reshape(, (len(theta),ny)) # genarating Vec_sinogram_image from radonmatrix and reshaping into 2d \n",
        "        sinogram_noisy = sinogram + self.noise_level*torch.randn(sinogram.shape) #Adding Noise to the image \n",
        "        return sinogram_noisy,label"
      ],
      "metadata": {
        "id": "i97LboRSs3ez"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta = np.linspace(0.,180.,26, endpoint=False)  # theta values\n",
        "A = torch.from_numpy(getRadonMatrix(theta,ny,nx))  # generating A matrix \n",
        "trainset =SinogramDataset(input_traindata,A,theta,0.1) # genarating a train_dataset\n",
        "print(A.shape)\n",
        "pseudo_inverse_of_A = torch.from_numpy(np.linalg.pinv(A))\n",
        "print(pseudo_inverse_of_A.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOsBIvANCp4e",
        "outputId": "9d203c5e-1a4f-4355-aaf0-9f78093d09e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/radon_transform.py:83: UserWarning: Radon transform: image must be zero outside the reconstruction circle\n",
            "  warn('Radon transform: image must be zero outside the '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([728, 784])\n",
            "torch.Size([784, 728])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sinogram_noisy, label = trainset[6]\n",
        "print(sinogram_noisy.shape)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
        "        \n",
        "ax1.set_title('IMAGE')\n",
        "ax1.imshow(torch.reshape(sinogram_noisy,(len(theta),ny)),cmap ='gray')\n",
        "\n",
        "ax2.set_title('GROUND TRUTH')\n",
        "ax2.imshow(label,cmap = 'gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "6mY0WxvTTBfp",
        "outputId": "11a8c30e-cc25-4557-d4bd-f6288c54d0ea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 728])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f309d7fd690>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=60, shuffle=True)\n",
        "batch_size=60\n"
      ],
      "metadata": {
        "id": "wNR1DOcjEOV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PrimalDualNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PrimalDualNetwork,self).__init__()\n",
        "        hidden = 4\n",
        "#        self.fc1 = nn.Linear(A.size()[1], hidden)\n",
        "        self.conv1image = nn.Conv2d(1, hidden, 3, padding=1)\n",
        "        self.conv2image = nn.Conv2d(hidden,1, 3, padding=1)\n",
        "        self.conv1sino = nn.Conv2d(1, hidden, 3, padding=1)\n",
        "        self.conv2sino = nn.Conv2d(hidden,1, 3, padding=1)\n",
        "#        self.fc2 = nn.Linear(hidden, A.size()[1])\n",
        "        \n",
        "        \n",
        "    def forward(self, sinogram,inv_A,maxiter,tau,A):   \n",
        "        # A needs to be of dimension: (sinogram_dimension x image_pixels)\n",
        "        # sinogram will be of dimension: (number_of_examples (batchsize)  x  sinogram_dimension)\n",
        "        output =  sinogram @ inv_A.T\n",
        "\n",
        "        for i in range(maxiter):\n",
        "            # possible here: Design a small sinogramCNN on err!\n",
        "            err = (output@A.T - sinogram)\n",
        "            err = torch.reshape(err,(batch_size,1,len(theta),ny))\n",
        "            err = self.conv2sino(nn.functional.relu(self.conv1sino(err)))\n",
        "\n",
        "            intermediateOutput = output - tau * err@A\n",
        "            output = self.conv2image(nn.functional.relu(self.conv1image(intermediateOutput)))\n",
        "            # in the above notation imageSpaceCNN = self.conv2(nn.functional.relu(self.conv1( * )))\n",
        "            \n",
        "        return output \n",
        "        "
      ],
      "metadata": {
        "id": "0kwzlly-JNb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "JG3WggAOdRs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(data_loader, model, optimizer):\n",
        "  model.train()\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  for i,ele in enumerate(trainloader):\n",
        "      batch_input,batch_output = ele\n",
        "      prediction = model(batch_input,pseudo_inverse_of_A,5,0.01,A)\n",
        "      optimizer.zero_grad()\n",
        "      loss = criterion(prediction, batch_output)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "  return loss"
      ],
      "metadata": {
        "id": "-zgqmj3gUVBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4wh1l-3uJfwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = PrimalDualNetwork()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "number_of_epochs = 10\n",
        "for epoch in range(number_of_epochs):\n",
        "  train_loss = train_fn(trainloader, model, optimizer)\n",
        "  \n",
        "    \n",
        "  if epoch%1==0:\n",
        "    print(f\"Epoch :{epoch+1} Train_loss : {train_loss}\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "28mi4gEoKB8Q",
        "outputId": "f4ad73ac-6f47-4cbb-8374-83267a123e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-218e3733b3e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnumber_of_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-134-d5276d284e10>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(data_loader, model, optimizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mbatch_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mele\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpseudo_inverse_of_A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-133-f39293693845>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sinogram, inv_A, maxiter, tau, A)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msinogram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2sino\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1sino\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mintermediateOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 444\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "h6Zc4bMrKB4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for index,data in enumerate(trainloader):\n",
        "  sinogram,image = data\n",
        "  print(sinogram.size())\n",
        "  print(image.size())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7uYExnwSmjV",
        "outputId": "0d4e1891-2816-47ec-e7fc-2663a18e000a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60, 26, 28])\n",
            "torch.Size([60, 28, 28])\n"
          ]
        }
      ]
    }
  ]
}